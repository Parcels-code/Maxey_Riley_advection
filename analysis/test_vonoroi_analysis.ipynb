{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://kraina-ai.github.io/srai/latest/examples/regionalizers/voronoi_regionalizer/\n",
    "\n",
    "If particles are at the same place (or too close) it cannot draw voronoi cells, the solution is to just devide the area of these too close cells by 2. I checked that this is coing correctly, but is is as the region_id is conserved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update reading in packages when rerunning this cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import Point, shape, Polygon, MultiPolygon\n",
    "from shapely import geometry\n",
    "from shapely.ops import unary_union\n",
    "from srai.loaders.osm_loaders import OSMOnlineLoader\n",
    "from srai.loaders.osm_loaders.filters.popular import get_popular_tags\n",
    "from functional import seq\n",
    "\n",
    "from srai.constants import WGS84_CRS\n",
    "from srai.plotting.folium_wrapper import plot_regions\n",
    "from srai.regionalizers import VoronoiRegionalizer, geocode_to_region_gdf, AdministrativeBoundaryRegionalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors \n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "import branca.colormap as cm_branca\n",
    "import sys\n",
    "sys.path.append(\"/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/src\")\n",
    "from analysis_functions import  make_PDF, make_lognormal_PDF\n",
    "from voronoi_functions import * \n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "\n",
    "# set plotscale\n",
    "plt.style.use('../python_style_Meike.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create sea mask polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing GEOjson file with boundaries of all countries\n",
    "# data downloaded from https://ec.europa.eu/eurostat/web/gisco/geodata/administrative-units/countries (make sure you download data in EPSG:4326 =WGS84 projection)\n",
    "\n",
    "europe = gpd.read_file(\"/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/input_data/europe.geojson\")\n",
    "# list of countries in the domain\n",
    "country_names = ['France','Germany','Denmark','Belgium','Netherlands','Bailiwick of Jersey','Jersey','Guernsey','Bailiwick of Guernsey','Isle of Man','United Kingdom','Ireland','Norway','Switzerland','Luxembourg','Italy','Liechtenstein','Austria']\n",
    "\n",
    "lon_min = -15.996014595031738+0.5\n",
    "lon_max = 9.977004051208496-0.5\n",
    "lat_min = 46.00364303588867+0.5\n",
    "lat_max = 61.28188705444336-0.5\n",
    "\n",
    "domaingdf = create_simulation_domain(\n",
    "    lon_min = lon_min,\n",
    "    lon_max = lon_max,\n",
    "    lat_min = lat_min,\n",
    "    lat_max = lat_max\n",
    "    )\n",
    "\n",
    "seagdf = create_sea_mask_polygon(region = domaingdf, land_boundaries = europe, countries_name_engl = country_names)\n",
    "\n",
    "\n",
    "# seagdf.explore()\n",
    "seagdf.to_file('/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/input_data/NWES_sea_mask.geojson', driver='GeoJSON') \n",
    "domaingdf.to_file('/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/input_data/NWES_sim_domain.geojson', driver='GeoJSON') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make small selection region\n",
    "lon_min = 0\n",
    "lon_max = 9.977004051208496-0.5\n",
    "lat_min = 50\n",
    "lat_max = 61.28188705444336-0.5\n",
    "\n",
    "domaingdf_small_region = create_simulation_domain(\n",
    "    lon_min = lon_min,\n",
    "    lon_max = lon_max,\n",
    "    lat_min = lat_min,\n",
    "    lat_max = lat_max\n",
    "    )\n",
    "\n",
    "seagdf_small_region = create_sea_mask_polygon(region = domaingdf_small_region, land_boundaries = europe, countries_name_engl = country_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make small selection region\n",
    "lon_min = 5.5 #-15.996014595031738+0.5\n",
    "lon_max = 6#9.977004051208496-0.5\n",
    "lat_min = 57# 46.00364303588867+0.5\n",
    "lat_max = 58 # 61.28188705444336-0.5\n",
    "\n",
    "#POINT (5.798840045928955 57.940521240234375)\n",
    "\n",
    "domaingdf_small_region = create_simulation_domain(\n",
    "    lon_min = lon_min,\n",
    "    lon_max = lon_max,\n",
    "    lat_min = lat_min,\n",
    "    lat_max = lat_max\n",
    "    )\n",
    "\n",
    "seagdf2 = create_sea_mask_polygon(region = domaingdf_small_region, land_boundaries = europe, countries_name_engl = country_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or read in already created seamask polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seagdf = gpd.GeoDataFrame.from_file('/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/input_data/NWES_sea_mask.geojson')\n",
    "# seagdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vonoroi for simulation data data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data (test dataset is tracer september)\n",
    "base_directory = '/storage/shared/oceanparcels/output_data/data_Meike/MR_advection/NWES/'\n",
    "input_file_tracer_base = (base_directory + '{particle_type}/{loc}_start{y_s:04d}_{m_s:02d}_{d_s:02d}'\n",
    "                   '_end{y_e:04d}_{m_e:02d}_{d_e:02d}_RK4_{land_handling}.zarr')\n",
    "\n",
    "runtime =  timedelta(days=30)# timedelta(days=10)\n",
    "loc = 'NWES'\n",
    "runtime=timedelta(30)\n",
    "nparticles = 88347 # 52511\n",
    "chunck_time = 100\n",
    "land_handling = 'anti_beaching'\n",
    "coriolis = True\n",
    "starttime = datetime(2023, 9, 1, 0, 0, 0, 0)\n",
    "endtime = starttime + runtime\n",
    "\n",
    "input_file_tracer = input_file_tracer_base.format(loc=loc,\n",
    "                                                        y_s=starttime.year,\n",
    "                                                        m_s=starttime.month,\n",
    "                                                        d_s=starttime.day,\n",
    "                                                        y_e=endtime.year,\n",
    "                                                        m_e=endtime.month,\n",
    "                                                        d_e=endtime.day,\n",
    "    \n",
    "                                                        land_handling = land_handling, \n",
    "                                                        cor_on = coriolis,\n",
    "                                                        particle_type = 'tracer')\n",
    "print(input_file_tracer)\n",
    "ds = xr.open_dataset(input_file_tracer,\n",
    "                        engine='zarr',\n",
    "                        chunks={'trajectory':nparticles, 'obs':chunck_time},\n",
    "                        drop_variables=['B','tau','z'],\n",
    "                        decode_times=False) #,decode_cf=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile =  '/storage/shared/oceanparcels/output_data/data_Meike/MR_advection/NWES/inertial_SM_Rep_constant/NWES_start2023_09_01_end2023_10_01_RK4__Rep_0000_B0680_tau2994_anti_beaching_cor_True_gradient_True.zarr'\n",
    "\n",
    "ds = xr.open_dataset(inputfile,\n",
    "                        engine='zarr',\n",
    "                        chunks={'trajectory':nparticles, 'obs':chunck_time},\n",
    "                        drop_variables=['B','tau','z'],\n",
    "                        decode_times=False) #,decode_cf=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "T=719\n",
    "pointlist = from_dataset_to_points(ds = ds, T= T, sea_domain=seagdf)\n",
    "pointlist_selection = random.sample(pointlist, 1000)\n",
    "seedsgdf = make_unique_seeds(points = pointlist)\n",
    "\n",
    "# make array with extra doubles\n",
    "pointlist_selection_with_doubles = pointlist_selection\n",
    "pointlist_selection_with_doubles.extend(pointlist_selection[0:100])\n",
    "seedsgdf_with_doubles = make_unique_seeds(points = pointlist_selection_with_doubles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_cells = make_regional_voronoi_tesselation(unique_seeds=seedsgdf, sea_region=seagdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_double = np.count_nonzero(seedsgdf.duplicates.values==2)\n",
    "n_unique = np.count_nonzero(seedsgdf.duplicates.values==1)\n",
    "\n",
    "print(f'# doubles for original list = {n_double}')\n",
    "print(f'# unique values for original list = {n_unique}')\n",
    "\n",
    "n_double = np.count_nonzero(seedsgdf_with_doubles.duplicates.values==2)\n",
    "n_unique = np.count_nonzero(seedsgdf_with_doubles.duplicates.values==1)\n",
    "print(f'# doubles for list with added doubles = {n_double}')\n",
    "print(f'# unique values for  list with added doubles = {n_unique}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_cells_doubles_small_region = make_regional_voronoi_tesselation(unique_seeds=seedsgdf_with_doubles, sea_region=seagdf_small_region)\n",
    "voronoi_small_region = make_regional_voronoi_tesselation(unique_seeds=seedsgdf, sea_region=seagdf_small_region)\n",
    "voronoi_cells_doubles = make_regional_voronoi_tesselation(unique_seeds=seedsgdf_with_doubles, sea_region=seagdf)\n",
    "voronoi_cells = make_regional_voronoi_tesselation(unique_seeds=seedsgdf, sea_region=seagdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show that region id is conserved and thus duplicates are copied correctly :) \n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(voronoi_cells.index.values,voronoi_cells.duplicates.values,'s',color='black',markersize=12)\n",
    "ax.plot(voronoi_small_region.index.values,voronoi_small_region.duplicates.values,'o',color='cyan',markersize=10)\n",
    "ax.plot(voronoi_cells_doubles.index.values,voronoi_cells_doubles.duplicates.values,'>',color='orange',markersize=8)\n",
    "ax.plot(voronoi_cells_doubles_small_region.index.values,voronoi_cells_doubles_small_region.duplicates.values,'P',color='purple',markersize=6)\n",
    "\n",
    "ax.set_xlabel('region id')\n",
    "ax.set_ylabel('# duplicates')\n",
    "ax.legend(['no added doubles, full region','no added doubles, small region','added doubles, full region','added doubles, small region'],loc=(1,0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": ccrs.PlateCarree()},figsize=(12,8))\n",
    "ax.add_feature(cfeature.LAND, edgecolor=\"black\", color=\"lightgray\")\n",
    "plot_voronoi(fig, ax , voronoi_cells,colormap = cm.Blues,\n",
    "             colormap_scale = 'log',\n",
    "             color_scale_type = 'density',\n",
    "            #  vmin = 1E-3,\n",
    "            #  vmax = 1E1, \n",
    "             colorbar_on =False)\n",
    "\n",
    "# gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "#             linewidth=0, color='gray', alpha=0.5, linestyle='--')\n",
    "# gl.top_labels = False\n",
    "# gl.right_labels = False\n",
    "# gl.xlabel_style = {'size': 15}\n",
    "# gl.ylabel_style =  {'size': 15}\n",
    "ax.set_frame_on(False)\n",
    "# fig.tight_layout()\n",
    "# fig.savefig('../figures/poster/voronoi_tesselation_NWES.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(voronoi_cells.duplicates.values-voronoi_cells2.duplicates.values,(voronoi_cells.density.values-voronoi_cells2.density.values)/voronoi_cells.density.values,'o')\n",
    "# ax.plot(,'o')\n",
    "# ax.plot(voronoi_cells2.density.values,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_cells.duplicates.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile = '/storage/shared/oceanparcels/output_data/data_Meike/MR_advection/NWES/inertial_SM_Rep_constant/voronoi_data/NWES_start2023_09_01_T0719h_Rep_0000B0680_tau2994_cor_True_gradient_True.geojson'\n",
    "voronoi_cells.to_file(outputfile, driver='GeoJSON') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vonoroi diagrams and calculate their area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vonoroi diagrams and calculate their area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_results.to_file('data/geojson_sea_results.geojson', driver='GeoJSON') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_results.to_file('data/shp_sea_result.shp') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_results.to_file('data/gpkg_sea_result.gpkg', driver='GPKG', layer='name')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_results.to_parquet('data/parquet_sea_ressults.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_read = gpd.read_file('data/test_sea_result.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_read_parquet = gpd.read_parquet('data/parquet_sea_ressults.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules\n",
    "import os\n",
    "\n",
    "# directory name from which\n",
    "# we are going to extract our files with its size\n",
    "path = \"/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/analysis/data\"\n",
    "\n",
    "# Get list of all files only in the given directory\n",
    "fun = lambda x : os.path.isfile(os.path.join(path,x))\n",
    "files_list = filter(fun, os.listdir(path))\n",
    "\n",
    "# Create a list of files in directory along with the size\n",
    "size_of_file = [\n",
    "\t(f,os.stat(os.path.join(path, f)).st_size)\n",
    "\tfor f in files_list\n",
    "]\n",
    "\n",
    "# Iterate over list of files along with size \n",
    "# and print them one by one.\n",
    "for f,s in size_of_file:\n",
    "\tprint(\"{} : {}MB\".format(f, round(s/(1024*1024),3)))\n",
    "\n",
    "#  parquet is smallest so will use that one to save data (still big though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize area values to range between 0 and 1\n",
    "vmin, vmax = sea_results[\"density\"].min(), sea_results[\"density\"].max()\n",
    "vmin = 0.1\n",
    "vmax = 100\n",
    "norm = colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "\n",
    "color_list = [colors.to_hex(cm.magma(norm(v))) for v in np.linspace(vmin, vmax, 12)]\n",
    "\n",
    "colormap = cm_branca.LinearColormap(\n",
    "    colors=color_list,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    caption=\"Polygon Area\"\n",
    ")\n",
    "# norm = colors.Normalize(vmin=12400, vmax=20000)\n",
    "\n",
    "# Generate colors based on normalized area values\n",
    "sea_results[\"color\"] = sea_results[\"area\"].apply(lambda x: colors.to_hex(cm.magma(norm(x))))\n",
    "\n",
    "# Use the 'color' column in your plot function\n",
    "folium_map = plot_regions(\n",
    "    sea_results,\n",
    "    colormap=list(sea_results[\"color\"]),  # Passing as a list of colors\n",
    "    tiles_style=\"CartoDB positron\",\n",
    "    show_borders=False\n",
    ")\n",
    "\n",
    "# sea_results.explore(\n",
    "#     m=folium_map,\n",
    "#     style_kwds=dict(\n",
    "#         color=\"#444\",  # Border color (can be ignored if weight is 0)\n",
    "#         weight=0,  # Set the line width to zero to remove borders\n",
    "#         fillOpacity=1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "colormap.add_to(folium_map)\n",
    "# # Add colormap to the map for reference\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 15), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "ax.add_feature(cfeature.LAND, edgecolor=\"black\", color=\"lightgray\")\n",
    "plot_voronoi(fig = fig,ax = ax, \n",
    "             voronoi_cells = voronoi_cells , \n",
    "             color_scale_type= 'area', \n",
    "             colormap = cm.magma, \n",
    "             vmin = 0.01, \n",
    "             vmax = 10, \n",
    "             colormap_scale='log')\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "            linewidth=0, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 15}\n",
    "gl.ylabel_style =  {'size': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bins, pdf = make_PDF(np.array(voronoi_cells['density'].values),nbins=100, norm = True, vmin = 0, vmax = 0.01)\n",
    "ax.plot(bins,pdf,'--o')\n",
    "# ax.set_xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logbins, logpdf = make_lognormal_PDF(np.array(voronoi_cells['density'].values),nbins=100, norm = True)\n",
    "plt.plot(logbins,logpdf,'--o')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf, bin_edges = np.histogram(np.array(voronoi_cells['area'].values), bins=1000)#s, range=(vmin, vmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 0\n",
    "max = 15 \n",
    "nbins = 16\n",
    "test = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "\n",
    "dx = (max - min) / nbins\n",
    "pdf, bin_edges = np.histogram(test, bins=nbins, range = (min,max))\n",
    "bins = bin_edges[:-1]+0.5*dx\n",
    "norm = test.size\n",
    "plt.plot(bins,pdf/norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geometric mean (I think better)\n",
    "print(np.exp(np.mean(np.log(np.array(voronoi_cells['density'].values)))))\n",
    "print(np.exp(np.mean(np.log(np.array(voronoi_cells['area'].values)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_density = np.mean(np.sort(np.array(voronoi_cells['density'].values))[1:-1])\n",
    "mean_area = np.mean(np.sort(np.array(voronoi_cells['area'].values))[1:-1])\n",
    "print(f'<rho> = {mean_density}, 1/<A> = {1/mean_area}')\n",
    "print(f'<A> = {mean_area}, 1/<rho> = {1/mean_density}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minx, miny, maxx, maxy = seagdf.total_bounds\n",
    "print(minx)\n",
    "print(miny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedsgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis area list\n",
    "# see https://epsg.io/25832-1149 for epsg 25832 projection seems fine, but maybe find someone who has more experience with projections\n",
    "arealist = sea_results.to_crs(epsg =25832).area\n",
    "# print(arealist.type)\n",
    "areas=[]\n",
    "for _, area in arealist.items():\n",
    "    areas.append(area/10**6)\n",
    "\n",
    "    \n",
    "areas = np.array(areas)\n",
    "print(areas.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.sort(areas),'o')\n",
    "mean_area=np.mean(areas)#np.sort(areas)[1000:-1000])\n",
    "print(mean_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, pdf = make_PDF(np.array(list(sea_results['density'])),nbins=200000000,norm=True)\n",
    "# mean_area=np.mean(areas)\n",
    "# print(mean_area)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot((bins+bins[1]),pdf[:],'--o',color='navy')\n",
    "ax.axvline(1,color='grey',zorder=-5)\n",
    "# ax.set_xscale('log')\n",
    "ax.set_xlabel('area / $\\\\langle$ area $\\\\rangle$')\n",
    "ax.set_ylabel('PDF')\n",
    "ax.set_xlim(0,0.2)\n",
    "ax.axvline(1/36.129062164\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binold = bins\n",
    "pdfold = pdf\n",
    "mean_area_old = 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot((bins[1:]+bins[1])/mean_area,pdf[1:],'--o',color='navy')\n",
    "ax.plot((binold[1:]+binold[1])/mean_area_old,pdfold[1:],'--o',color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing initial position \n",
    "The vonoroi cells at early timesteps where not hexagonal which was suspisous? So below I check this with making a subset hexagonal distribution. Found a mistake in the initialization which I updated and now the vonoroi cells also become hexagons \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed packages\n",
    "#update reading in packages when rerunning this cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import h3\n",
    "sys.path.append(\"/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/release\")\n",
    "import h3_tools\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy as cart\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set particles on hexagonal grid in region\n",
    "seagdf = gpd.GeoDataFrame.from_file('/nethome/4291387/Maxey_Riley_advection/Maxey_Riley_advection/input_data/NWES_sea_mask.geojson')\n",
    "NWES_domain = { \n",
    "    \"type\":\"Polygon\",\n",
    "    \"coordinates\": [\n",
    "   [[9.977004051208496-0.5,61.28188705444336-0.5],\n",
    "     [-15.996014595031738+0.5,61.28188705444336-0.5],\n",
    "     [-15.996014595031738+0.5,46.00364303588867+0.5],\n",
    "     [9.977004051208496-0.5,46.00364303588867+0.5],\n",
    "     [9.977004051208496-0.5,61.28188705444336-0.5]]\n",
    "     ]}\n",
    "\n",
    "NWES_domain_Flipped = {\n",
    "      \"type\": \"Polygon\",\n",
    "      \"coordinates\": [[[lat, lon] for lon, lat in NWES_domain[\"coordinates\"][0]]]}\n",
    "NWESParticles = h3_tools.initGrid(NWES_domain, h3_res=3)\n",
    "NWES_shape = shape(NWES_domain)\n",
    "print(NWESParticles.centroid_lons[0])\n",
    "# print(f\"Number of particles: {NWESParticles.size}\")\n",
    "\n",
    "# # plot partciles together with region\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# ax = plt.axes(projection=cart.crs.PlateCarree())\n",
    "# ax.add_feature(cart.feature.LAND)\n",
    "# ax.add_feature(cart.feature.OCEAN)\n",
    "# ax.add_feature(cart.feature.COASTLINE)\n",
    "# ax.add_feature(cart.feature.BORDERS, linestyle=':')\n",
    "# ax.gridlines(draw_labels=True, linestyle='--', color='gray', alpha=0.5, linewidth=0.5)\n",
    "\n",
    "# ax.scatter(NWESParticles.centroid_lons, NWESParticles.centroid_lats, transform=cart.crs.PlateCarree(), s=0.5, c='r')\n",
    "# ax.add_geometries([NWES_shape], cart.crs.PlateCarree(), facecolor='lightblue', edgecolor='black', alpha=0.5)\n",
    "# ax.set_xlim(-20,15)\n",
    "# ax.set_ylim(40,70)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# #set mask for new dataset\n",
    "mask = xr.open_dataset('/storage/shared/oceanparcels/input_data/CopernicusMarineService/NORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013/CMEMS_v6r1_NWS_PHY_NRT_NL_01hav3D_20231204_20231204_R20231205_HC01.nc').isel(time=0).isel(depth=0)\n",
    "lats, lons = np.meshgrid(mask.latitude.values,mask.longitude.values,indexing='ij') \n",
    "full_water =~np.isnan(mask.uo.values.T)\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# ax = plt.axes(projection=cart.crs.PlateCarree())\n",
    "# ax.add_feature(cart.feature.LAND)\n",
    "# ax.add_feature(cart.feature.OCEAN)\n",
    "# ax.add_feature(cart.feature.COASTLINE)\n",
    "# ax.add_feature(cart.feature.BORDERS, linestyle=':')\n",
    "# ax.gridlines(draw_labels=True, linestyle='--', color='gray', alpha=0.5, linewidth=0.5)\n",
    "\n",
    "# ax.scatter(lons[full_water.T], lats[full_water.T], transform=cart.crs.PlateCarree(), s=0.5, c='r')\n",
    "# ax.add_geometries([NWES_shape], cart.crs.PlateCarree(), facecolor='lightblue', edgecolor='black', alpha=0.5)\n",
    "# ax.set_xlim(-20,15)\n",
    "# ax.set_ylim(40,70)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # use mask on particles\n",
    "NWESParticles.mask(lons, lats, full_water.T)\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "# ax = plt.axes(projection=cart.crs.PlateCarree())\n",
    "# ax.add_feature(cart.feature.LAND)\n",
    "# ax.add_feature(cart.feature.OCEAN)\n",
    "# ax.add_feature(cart.feature.COASTLINE)\n",
    "# ax.add_feature(cart.feature.BORDERS, linestyle=':')\n",
    "# ax.gridlines(draw_labels=True, linestyle='--', color='gray', alpha=0.5, linewidth=0.5)\n",
    "\n",
    "# ax.scatter(NWESParticles.centroid_lons, NWESParticles.centroid_lats, transform=cart.crs.PlateCarree(), s=0.5, c='r')\n",
    "# ax.add_geometries([NWES_shape], cart.crs.PlateCarree(), facecolor='lightblue', edgecolor='black', alpha=0.5)\n",
    "\n",
    "# ax.set_xlim(-20,15)\n",
    "# ax.set_ylim(40,70)\n",
    "\n",
    "# plt.show()\n",
    "print(f\"Number of particles: {NWESParticles.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NWESParticles.centroid_lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointlist_initial = [Point(lon, lat) for lon, lat  in zip(NWESParticles.centroid_lons, NWESParticles.centroid_lats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_initial = gpd.GeoDataFrame(\n",
    "    {\"geometry\": pointlist_initial},\n",
    "    index=list(range(len(pointlist_initial))),\n",
    "    crs=WGS84_CRS,\n",
    ")\n",
    "print(seeds_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_initial = VoronoiRegionalizer(seeds=seeds_initial)\n",
    "sea_initial_results = vr_initial.transform(gdf = seagdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_units = sea_initial_results.to_crs(epsg=3395)\n",
    "sea_initial_results[\"area\"] = change_units.geometry.area/1E6\n",
    "sea_initial_results = sea_initial_results.sort_index()\n",
    "print(sea_initial_results[\"area\"].min())\n",
    "print(sea_initial_results[\"area\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors \n",
    "import branca.colormap as cm_branca\n",
    "\n",
    "# Normalize area values to range between 0 and 1\n",
    "vmin, vmax = sea_initial_results[\"area\"].min(), sea_initial_results[\"area\"].max()\n",
    "vmin = 30000\n",
    "vmax = 40000\n",
    "norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "color_list = [colors.to_hex(cm.viridis(norm(v))) for v in np.linspace(vmin, vmax, 12)]\n",
    "\n",
    "colormap = cm_branca.LinearColormap(\n",
    "    colors=color_list,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    caption=\"Polygon Area\"\n",
    ")\n",
    "# norm = colors.Normalize(vmin=12400, vmax=20000)\n",
    "\n",
    "# Generate colors based on normalized area values\n",
    "sea_initial_results[\"color\"] = sea_initial_results[\"area\"].apply(lambda x: colors.to_hex(cm.viridis(norm(x))))\n",
    "\n",
    "# Use the 'color' column in your plot function\n",
    "folium_map = plot_regions(\n",
    "    sea_initial_results,\n",
    "    colormap=list(sea_initial_results[\"color\"]),  # Passing as a list of colors\n",
    "    tiles_style=\"CartoDB positron\"\n",
    ")\n",
    "\n",
    "\n",
    "colormap.add_to(folium_map)\n",
    "# Add colormap to the map for reference\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_initial_results.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium_map = plot_regions(\n",
    "    sea_initial_results, \n",
    "    colormap=colormap, \n",
    "    tiles_style=\"CartoDB positron\"\n",
    ")\n",
    "\n",
    "# Add the polygons with color based on area\n",
    "sea_initial_results.explore(\n",
    "    m=folium_map,\n",
    "    style_kwds=lambda feature: {\n",
    "        \"color\": \"#444\",\n",
    "        \"opacity\": 0,\n",
    "        \"fillColor\": colormap(feature[\"properties\"][\"area\"]),\n",
    "        \"fillOpacity\": 1\n",
    "    },\n",
    "    marker_kwds=dict(radius=1),\n",
    ")\n",
    "\n",
    "# Add colormap to the map for reference\n",
    "colormap.add_to(folium_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reading in data from script \n",
    "test = gpd.GeoDataFrame.from_file('/storage/shared/oceanparcels/output_data/data_Meike/MR_advection/NWES/tracer/voronoi_data/NWES_start2023_09_01_T0719h.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, pdf  = make_lognormal_PDF(test['density'].values,nbins =100, norm =True)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(bins, pdf,'--o')\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking simulation for which script does not work (MRSM, sep 2023, rep=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/storage/shared/oceanparcels/output_data/data_Meike/MR_advection/NWES/tracer_random/NWES_start2024_01_01_end2024_01_31_RK4_d0300_anti_beaching.zarr',engine=\"zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(5.798840045928955, 57.940521240234375,s=10,color='k')\n",
    "ax.scatter(ds.lon[:,719],ds.lat[:,719],s=2,alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lon[ntest,719].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointlist = from_dataset_to_points(ds = ds, T= 719, sea_domain=seagdf)\n",
    "npoints = np.array(pointlist).size\n",
    "\n",
    "seedsgdf = make_unique_seeds(points = pointlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(seedsgdf.duplicates.values,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(0.0001,4)\n",
    "Rearth =6378 * 1000\n",
    "0.00001*np.pi/180 * Rearth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =0\n",
    "ntest = 9729\n",
    "for index, gdf in enumerate(seedsgdf.geometry):\n",
    "    # print(index)\n",
    "    if (n == ntest):\n",
    "        print(index)\n",
    "        print(gdf)\n",
    "    n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedsgdf2  = seedsgdf.drop(index = 8356)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_cells = make_regional_voronoi_tesselation(unique_seeds=seedsgdf2, sea_region=seagdf)\n",
    "\n",
    "# this gives error: \n",
    "# File /storage/home/4291387/parcels_env/lib/python3.12/site-packages/scipy/spatial/_spherical_voronoi.py:261, in SphericalVoronoi.sort_vertices_of_regions(self)\n",
    "#     259 if self._dim != 3:\n",
    "#     260     raise TypeError(\"Only supported for three-dimensional point sets\")\n",
    "# --> 261 _voronoi.sort_vertices_of_regions(self._simplices, self.regions)\n",
    "\n",
    "# File _voronoi.pyx:37, in scipy.spatial._voronoi.sort_vertices_of_regions()\n",
    "\n",
    "# ValueError: Buffer dtype mismatch, expected 'npy_intp' but got 'double'\n",
    "\n",
    "# which is not caused by points too close to eachother (that would give error:\n",
    "# --> 189     raise ValueError(\"Duplicate generators present.\")\n",
    "#     191 radii = np.linalg.norm(self.points - self.center, axis=1)\n",
    "#     192 max_discrepancy = np.abs(radii - self.radius).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_per_particle = make_value_list_per_particle(voronoi_cells,'density')\n",
    "bins, pdf = make_lognormal_PDF(density_per_particle,norm=True,nbins=100,vmin=1E-3,vmax=1E0)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(bins,pdf)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######## import data #########\n",
    "# settings for input data\n",
    "pt = 'tracer_random'#'inertial_SM_Rep_constant'#'inertial_SM_drag_Rep'# \"tracer\"\n",
    "loc = \"NWES\"\n",
    "land_handling = \"anti_beaching\"\n",
    "coriolis = True\n",
    "B = 0.68\n",
    "tau = 2994.76\n",
    "nparticles = 88347\n",
    "chunck_time = 1000\n",
    "\n",
    "t_res = 'daily'\n",
    "t_res_names = {'daily':'tres_daily_',\n",
    "              'hourly':''}\n",
    "starttime = datetime(2024, 1, 1)\n",
    "Rep = 0\n",
    "displacement = 300\n",
    "T = 719\n",
    "gradient = True\n",
    "runtime = timedelta(days=30)\n",
    "endtime = starttime + runtime\n",
    "\n",
    "    # basefiles to read in files\n",
    "data_directory = (\n",
    "    \"/storage/shared/oceanparcels/output_data/data_Meike/MR_advection/NWES/\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "outputfile_tracer = (\n",
    "    data_directory + \"{particle_type}/voronoi_data/{loc}_{time_resolution}_\"\n",
    "    \"start{y_s:04d}_{m_s:02d}_{d_s:02d}_T{T:04d}h.geojson\"\n",
    ")\n",
    "\n",
    "\n",
    "outputfile_tracer_random = (\n",
    "    data_directory + \"{particle_type}/voronoi_data/{loc}_{time_resolution}_\"\n",
    "    \"start{y_s:04d}_{m_s:02d}_{d_s:02d}_T{T:04d}h.geojson\"\n",
    ")\n",
    "\n",
    "outputfile_MR = (\n",
    "    data_directory + \"{particle_type}/voronoi_data/{loc}_{time_resolution}_\"\n",
    "    \"start{y_s:04d}_{m_s:02d}_{d_s:02d}_T{T:04d}h_\"\n",
    "    \"B{B:04d}_tau{tau:04d}_cor_{coriolis}_gradient_{gradient}.geojson\"\n",
    ")\n",
    "\n",
    "outputfile_MR_Rep_constant = (\n",
    "    data_directory + \"{particle_type}/voronoi_data/{loc}_{time_resolution}_\"\n",
    "    \"start{y_s:04d}_{m_s:02d}_{d_s:02d}_T{T:04d}h_Rep_{Rep:04d}\"\n",
    "    \"B{B:04d}_tau{tau:04d}_cor_{coriolis}_gradient_{gradient}.geojson\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outputfiles = {\n",
    "    \"tracer\": outputfile_tracer,\n",
    "    \"tracer_random\": outputfile_tracer_random,\n",
    "    \"inertial_Rep_constant\": outputfile_MR_Rep_constant,\n",
    "    \"inertial_SM_Rep_constant\": outputfile_MR_Rep_constant,\n",
    "    \"inertial_drag_Rep\": outputfile_MR,\n",
    "    \"inertial_SM_drag_Rep\": outputfile_MR,\n",
    "}\n",
    "\n",
    "\n",
    "outputfile = outputfiles[pt].format(\n",
    "    loc=loc,\n",
    "    y_s=starttime.year,\n",
    "    m_s=starttime.month,\n",
    "    d_s=starttime.day,\n",
    "    y_e=endtime.year,\n",
    "    m_e=endtime.month,\n",
    "    d_e=endtime.day,\n",
    "    land_handling=land_handling,\n",
    "    coriolis=coriolis,\n",
    "    particle_type=pt,\n",
    "    d = displacement,\n",
    "    Rep = Rep,\n",
    "    gradient = gradient,\n",
    "    B = int(1000*B),\n",
    "    tau = int(tau),\n",
    "    T=T,\n",
    "    time_resolution = t_res\n",
    ")\n",
    "\n",
    "print(outputfile)\n",
    "\n",
    "\n",
    "voronoi_cells.to_file(outputfile, driver='GeoJSON') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import SphericalVoronoi\n",
    "\n",
    "points = np.array([[0, 0, 1], [0, 0, -1], [1, 0, 0], [0, 1, 0], [0, -1, 0], [-1, 0, 0], \n",
    "                   [1,1,0], [1,-1,0], [-1,1,0], [-1,-1,0], [1,0,1], [1,0,-1], [-1,0,1], [-1,0,-1], [0,1,1], [0,1,-1], [0,-1,1],[0,-1,-1],\n",
    "                   [1,1,1], [1,1,-1], [1,-1,1], [1,-1,-1], [-1,1,1], [-1,1,-1], [-1,-1,1], [-1,-1,-1]], dtype=float)\n",
    "\n",
    "points /= np.sqrt((points**2).sum(axis=1))[:, np.newaxis]\n",
    "\n",
    "radius = 1.0\n",
    "center = np.array([0, 0, 0], dtype=float)\n",
    "sv = SphericalVoronoi(points, radius, center)\n",
    "\n",
    "sv._calc_vertices_regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.bincount([1,2,3,4,5,6,7,8,10])\n",
    "print(np.argwhere(test==0))\n",
    "print(np.cumsum(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = seagdf2.plot()\n",
    "ax.scatter(ds.lon[:,719],ds.lat[:,719],s=2,alpha=1,color='grey')\n",
    "ax.set_xlim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
